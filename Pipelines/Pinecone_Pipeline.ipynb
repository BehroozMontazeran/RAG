{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Embedding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_distilroberta_recursive_400_50.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't use OpenAI embedding as it costs money  multi-qa-mpnet-base-dot-v1\n",
    "embedding_model = 'sentence-transformers/all-distilroberta-v1'#'sentence-transformers/all-MiniLM-L6-v2' #all-mpnet-base-v2'\n",
    "\n",
    "device = 'cuda:0' # make sure you are on gpu\n",
    "batch_size = 32\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': batch_size}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = embed_model.embed_documents(data['text'])\n",
    "print(\"number of docs:\",len(embeddings))\n",
    "print(\"dimension of docs:\",len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the CSV file\n",
    "csv_file = '00embeddings.csv'\n",
    "\n",
    "# Writing embeddings to CSV\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write each embedding as a row in the CSV file\n",
    "    for embedding in embeddings:\n",
    "        writer.writerow(embedding)\n",
    "\n",
    "print(\"Embeddings saved to CSV file:\", csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embeddings'] = embeddings\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file = '0data_with_embeddings.csv'\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "data.to_csv(csv_file, index=False)\n",
    "\n",
    "print(\"Data with embeddings saved to CSV file:\", csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, emb in enumerate(embeddings):\n",
    "    print(f\"ID: {data['id'].iloc[i]}, Embedding: {emb}, source: {data['resource'].iloc[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Pinecone\n",
    "pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))\n",
    "index_name = 'medical-articles-embeddings'\n",
    "#initialize the index\n",
    "pc.create_index(\n",
    "    index_name,\n",
    "    dimension=384,#len(embeddings[0]),\n",
    "    metric='cosine',\n",
    "    spec= PodSpec(environment=\"gcp-starter\")\n",
    ")\n",
    "# Describe the index\n",
    "index_name = 'medical-articles-embeddings'\n",
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    batch = data.iloc[i:i_end]\n",
    "    ids = [f\"{x['id']}\" for _, x in batch.iterrows()]\n",
    "    texts = [x['text'] for _, x in batch.iterrows()]\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['text'],\n",
    "         'resource': x['source']} for _, x in batch.iterrows()\n",
    "    ]\n",
    "    # metadata = [\n",
    "    #     {'text': x['text']} for _, x in batch.iterrows()\n",
    "    # ]\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the scores for the top 5 matches\n",
    "query = 'who is Moog'\n",
    "\n",
    "# query\n",
    "results = index.query(vector=embed_model.embed_query(query), top_k=5, include_metadata=True)\n",
    "for result in results['matches']:\n",
    "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the top N results\n",
    "from langchain.vectorstores import Pinecone\n",
    "vectorstore = Pinecone(index, embed_model.embed_query, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'what is the cause of CASK Disorders?'\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # the search query\n",
    "    k=3  # returns top 3 most relevant chunks of text\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
